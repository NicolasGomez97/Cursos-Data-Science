{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7554ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Using cached findspark-2.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c81eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.2.0.tar.gz (281.3 MB)\n",
      "Collecting py4j==0.10.9.2\n",
      "  Using cached py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=252a156f8bcc64a346f7da5fb3a1d3f1a430f8eceb556b2e9f051cffa6887214\n",
      "  Stored in directory: c:\\users\\nicolas\\appdata\\local\\pip\\cache\\wheels\\23\\f6\\d3\\110e53bd43baeb8d7d38049733d48e39cbecd056f01dba7ee8\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5f226",
   "metadata": {},
   "source": [
    "### SparkSession crear y leer Dataframe en PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0cb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0770308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e9b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('firstSession').config('spark.master','local[4]').config('spark.shuffle.sql.partitions', 1).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e25c01cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-FF0DMO1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>firstSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c2ee1bd3d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771e0b7",
   "metadata": {},
   "source": [
    "Detener la palicacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9426e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539494c",
   "metadata": {},
   "source": [
    "## 2. Crear tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fcff0",
   "metadata": {},
   "source": [
    "### 2.1 A partir de una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4137c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['id','nombre','x']\n",
    "\n",
    "lista = [\n",
    "    (1,'Nicolas','a'),\n",
    "    (2,'Ramiro','b'),\n",
    "    (3,'Gomez','c'),\n",
    "    (4,'Nacho','d'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a594ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.createDataFrame(lista, schema=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0928212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuantas filas tiene\n",
    "df_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d62956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id| nombre|  x|\n",
      "+---+-------+---+\n",
      "|  1|Nicolas|  a|\n",
      "|  2| Ramiro|  b|\n",
      "|  3|  Gomez|  c|\n",
      "|  4|  Nacho|  d|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# muestra el dataframe\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64f27c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'nombre', 'x']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra el nombre de las columnas\n",
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ba6cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- x: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Muestra el tipo de datos de cada columna\n",
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0b917d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+----+\n",
      "|summary|                id|nombre|   x|\n",
      "+-------+------------------+------+----+\n",
      "|  count|                 4|     4|   4|\n",
      "|   mean|               2.5|  null|null|\n",
      "| stddev|1.2909944487358056|  null|null|\n",
      "|    min|                 1| Gomez|   a|\n",
      "|    max|                 4|Ramiro|   d|\n",
      "+-------+------------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Describe\n",
    "df_1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16a638c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71ab5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_1 = StructType(\n",
    "    [\n",
    "        StructField('id',IntegerType(), True),\n",
    "        StructField('nombre',StringType(), True),\n",
    "        StructField('y',StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3447ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = spark.createDataFrame(lista, schema= schema_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4226341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ddecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id| nombre|  y|\n",
      "+---+-------+---+\n",
      "|  1|Nicolas|  a|\n",
      "|  2| Ramiro|  b|\n",
      "|  3|  Gomez|  c|\n",
      "|  4|  Nacho|  d|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30711b17",
   "metadata": {},
   "source": [
    "### 2.2 A partir de un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08a5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70cfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
